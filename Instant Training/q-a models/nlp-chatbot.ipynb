{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b18f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:15:56.752894Z",
     "iopub.status.busy": "2023-07-24T06:15:56.752436Z",
     "iopub.status.idle": "2023-07-24T06:16:07.143029Z",
     "shell.execute_reply": "2023-07-24T06:16:07.141939Z"
    },
    "papermill": {
     "duration": 10.404833,
     "end_time": "2023-07-24T06:16:07.145787",
     "exception": false,
     "start_time": "2023-07-24T06:15:56.740954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49a4990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:07.170049Z",
     "iopub.status.busy": "2023-07-24T06:16:07.168137Z",
     "iopub.status.idle": "2023-07-24T06:16:08.514095Z",
     "shell.execute_reply": "2023-07-24T06:16:08.513091Z"
    },
    "papermill": {
     "duration": 1.359173,
     "end_time": "2023-07-24T06:16:08.516934",
     "exception": false,
     "start_time": "2023-07-24T06:16:07.157761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df= pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34341d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.539077Z",
     "iopub.status.busy": "2023-07-24T06:16:08.538726Z",
     "iopub.status.idle": "2023-07-24T06:16:08.565298Z",
     "shell.execute_reply": "2023-07-24T06:16:08.564062Z"
    },
    "papermill": {
     "duration": 0.041214,
     "end_time": "2023-07-24T06:16:08.568661",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.527447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_as_int</th>\n",
       "      <th>answer_as_int</th>\n",
       "      <th>question_len</th>\n",
       "      <th>answer_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>71</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n",
       "      <td>55</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n",
       "      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n",
       "      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n",
       "      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>221608</td>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n",
       "      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>221609</td>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n",
       "      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>221610</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n",
       "      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>221611</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>221612</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           question  \\\n",
       "0                1  Well, I thought we'd start with pronunciation,...   \n",
       "1                2  Not the hacking and gagging and spitting part....   \n",
       "2                3  You're asking me out.  That's so cute. What's ...   \n",
       "3                4  No, no, it's my fault -- we didn't have a prop...   \n",
       "4                9     Gosh, if only we could find Kat a boyfriend...   \n",
       "...            ...                                                ...   \n",
       "139404      221608    Well that one. The one who keeps looking at me.   \n",
       "139405      221609  Choose your targets men. That's right Watch th...   \n",
       "139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407      221611                           Your orders, Mr Vereker?   \n",
       "139408      221612  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \\\n",
       "0       Not the hacking and gagging and spitting part....   \n",
       "1       Okay... then how 'bout we try out some French ...   \n",
       "2                                              Forget it.   \n",
       "3                                                Cameron.   \n",
       "4                               Let me see what I can do.   \n",
       "...                                                   ...   \n",
       "139404  ft could be you flatter yourself CoghilL It's ...   \n",
       "139405  Keep steady. You're the best shots of the Twen...   \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n",
       "139407  I'm to take the Sikali with the main column to...   \n",
       "139408  Lord Chelmsford seems to want me to stay back ...   \n",
       "\n",
       "                                          question_as_int  \\\n",
       "0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n",
       "1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n",
       "2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n",
       "3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n",
       "4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n",
       "...                                                   ...   \n",
       "139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n",
       "139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n",
       "139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n",
       "139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n",
       "139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n",
       "\n",
       "                                            answer_as_int  question_len  \\\n",
       "0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n",
       "1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n",
       "2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n",
       "3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n",
       "4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n",
       "...                                                   ...           ...   \n",
       "139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n",
       "139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n",
       "139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n",
       "139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n",
       "139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n",
       "\n",
       "        answer_len  \n",
       "0               55  \n",
       "1               73  \n",
       "2               10  \n",
       "3                8  \n",
       "4               25  \n",
       "...            ...  \n",
       "139404          59  \n",
       "139405          85  \n",
       "139406          60  \n",
       "139407          56  \n",
       "139408          62  \n",
       "\n",
       "[139409 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382293e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.591198Z",
     "iopub.status.busy": "2023-07-24T06:16:08.590907Z",
     "iopub.status.idle": "2023-07-24T06:16:08.618367Z",
     "shell.execute_reply": "2023-07-24T06:16:08.617390Z"
    },
    "papermill": {
     "duration": 0.040742,
     "end_time": "2023-07-24T06:16:08.620620",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.579878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec72ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.642520Z",
     "iopub.status.busy": "2023-07-24T06:16:08.642230Z",
     "iopub.status.idle": "2023-07-24T06:16:08.743438Z",
     "shell.execute_reply": "2023-07-24T06:16:08.742388Z"
    },
    "papermill": {
     "duration": 0.114842,
     "end_time": "2023-07-24T06:16:08.745704",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.630862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139409 entries, 0 to 139408\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   question  139409 non-null  object\n",
      " 1   answer    139409 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b7a5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.769551Z",
     "iopub.status.busy": "2023-07-24T06:16:08.767835Z",
     "iopub.status.idle": "2023-07-24T06:16:08.780985Z",
     "shell.execute_reply": "2023-07-24T06:16:08.779813Z"
    },
    "papermill": {
     "duration": 0.027482,
     "end_time": "2023-07-24T06:16:08.783780",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.756298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       Well, I thought we'd start with pronunciation,...   \n",
       "1       Not the hacking and gagging and spitting part....   \n",
       "2       You're asking me out.  That's so cute. What's ...   \n",
       "3       No, no, it's my fault -- we didn't have a prop...   \n",
       "4          Gosh, if only we could find Kat a boyfriend...   \n",
       "...                                                   ...   \n",
       "139404    Well that one. The one who keeps looking at me.   \n",
       "139405  Choose your targets men. That's right Watch th...   \n",
       "139406  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407                           Your orders, Mr Vereker?   \n",
       "139408  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \n",
       "0       Not the hacking and gagging and spitting part....  \n",
       "1       Okay... then how 'bout we try out some French ...  \n",
       "2                                              Forget it.  \n",
       "3                                                Cameron.  \n",
       "4                               Let me see what I can do.  \n",
       "...                                                   ...  \n",
       "139404  ft could be you flatter yourself CoghilL It's ...  \n",
       "139405  Keep steady. You're the best shots of the Twen...  \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n",
       "139407  I'm to take the Sikali with the main column to...  \n",
       "139408  Lord Chelmsford seems to want me to stay back ...  \n",
       "\n",
       "[139409 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6848c16f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.808228Z",
     "iopub.status.busy": "2023-07-24T06:16:08.807950Z",
     "iopub.status.idle": "2023-07-24T06:16:08.817616Z",
     "shell.execute_reply": "2023-07-24T06:16:08.816624Z"
    },
    "papermill": {
     "duration": 0.024458,
     "end_time": "2023-07-24T06:16:08.819962",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.795504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C'esc ma tete. This is my head</td>\n",
       "      <td>Right.  See?  You're ready for the quiz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>That's because it's such a nice one.</td>\n",
       "      <td>Forget French.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How is our little Find the Wench A Date plan p...</td>\n",
       "      <td>Well, there's someone I think might be --</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You have my word.  As a gentleman</td>\n",
       "      <td>You're sweet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sure have.</td>\n",
       "      <td>I really, really, really wanna go, but I can't...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Well, I thought we'd start with pronunciation,...   \n",
       "1  Not the hacking and gagging and spitting part....   \n",
       "2  You're asking me out.  That's so cute. What's ...   \n",
       "3  No, no, it's my fault -- we didn't have a prop...   \n",
       "4     Gosh, if only we could find Kat a boyfriend...   \n",
       "5                     C'esc ma tete. This is my head   \n",
       "6               That's because it's such a nice one.   \n",
       "7  How is our little Find the Wench A Date plan p...   \n",
       "8                  You have my word.  As a gentleman   \n",
       "9                                         Sure have.   \n",
       "\n",
       "                                              answer  \n",
       "0  Not the hacking and gagging and spitting part....  \n",
       "1  Okay... then how 'bout we try out some French ...  \n",
       "2                                         Forget it.  \n",
       "3                                           Cameron.  \n",
       "4                          Let me see what I can do.  \n",
       "5           Right.  See?  You're ready for the quiz.  \n",
       "6                                     Forget French.  \n",
       "7          Well, there's someone I think might be --  \n",
       "8                                      You're sweet.  \n",
       "9  I really, really, really wanna go, but I can't...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b6f76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.844325Z",
     "iopub.status.busy": "2023-07-24T06:16:08.843628Z",
     "iopub.status.idle": "2023-07-24T06:16:08.857824Z",
     "shell.execute_reply": "2023-07-24T06:16:08.856629Z"
    },
    "papermill": {
     "duration": 0.029043,
     "end_time": "2023-07-24T06:16:08.860679",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.831636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50233</th>\n",
       "      <td>Well, your condition's pretty serious.</td>\n",
       "      <td>[Beat] So they say. [Off Becker's steady gaze]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62200</th>\n",
       "      <td>You already said that, Butt-Head.</td>\n",
       "      <td>Oh, uh, I mean, uh, ass-goblin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101524</th>\n",
       "      <td>Calm down.</td>\n",
       "      <td>That's easy for you to say! You can't get scar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74433</th>\n",
       "      <td>It's only a flesh wound.</td>\n",
       "      <td>It's only fourteen or fifteen flesh wounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478</th>\n",
       "      <td>Now, comrades... there is something better in ...</td>\n",
       "      <td>Yes, a good piece of apfel strudel....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49813</th>\n",
       "      <td>Maybe dinner.</td>\n",
       "      <td>Dogs don't eat each other.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25209</th>\n",
       "      <td>I know you. How come you're so tense today?</td>\n",
       "      <td>What can I tell you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134087</th>\n",
       "      <td>It might as well be fifteen-hundred dollars, b...</td>\n",
       "      <td>Then you ain't gonna have the car.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>Total delirium.</td>\n",
       "      <td>He'll never make it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35422</th>\n",
       "      <td>Yes, Leon...</td>\n",
       "      <td>What is it, my boy?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "50233              Well, your condition's pretty serious.   \n",
       "62200                   You already said that, Butt-Head.   \n",
       "101524                                         Calm down.   \n",
       "74433                            It's only a flesh wound.   \n",
       "35478   Now, comrades... there is something better in ...   \n",
       "49813                                       Maybe dinner.   \n",
       "25209         I know you. How come you're so tense today?   \n",
       "134087  It might as well be fifteen-hundred dollars, b...   \n",
       "25481                                     Total delirium.   \n",
       "35422                                        Yes, Leon...   \n",
       "\n",
       "                                                   answer  \n",
       "50233   [Beat] So they say. [Off Becker's steady gaze]...  \n",
       "62200                   Oh, uh, I mean, uh, ass-goblin...  \n",
       "101524  That's easy for you to say! You can't get scar...  \n",
       "74433         It's only fourteen or fifteen flesh wounds.  \n",
       "35478              Yes, a good piece of apfel strudel....  \n",
       "49813                          Dogs don't eat each other.  \n",
       "25209                                What can I tell you?  \n",
       "134087                 Then you ain't gonna have the car.  \n",
       "25481                                He'll never make it.  \n",
       "35422                                 What is it, my boy?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23374e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:08.884932Z",
     "iopub.status.busy": "2023-07-24T06:16:08.884632Z",
     "iopub.status.idle": "2023-07-24T06:16:14.990251Z",
     "shell.execute_reply": "2023-07-24T06:16:14.989250Z"
    },
    "papermill": {
     "duration": 6.119921,
     "end_time": "2023-07-24T06:16:14.992819",
     "exception": false,
     "start_time": "2023-07-24T06:16:08.872898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub('\\[.*?\\]', '', text)\n",
    "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "  text = re.sub('<.*?>+', '', text)\n",
    "  text = re.sub('\\n', '', text)\n",
    "  text = re.sub(r'[^\\w]',' ',text)\n",
    "  text = re.sub('\\w*\\d\\w*', '', text)\n",
    "  return text\n",
    "\n",
    "data_df.question = data_df.question.map(clean_text)\n",
    "data_df.answer = data_df.answer.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "220defa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:15.017184Z",
     "iopub.status.busy": "2023-07-24T06:16:15.016885Z",
     "iopub.status.idle": "2023-07-24T06:16:15.155445Z",
     "shell.execute_reply": "2023-07-24T06:16:15.154315Z"
    },
    "papermill": {
     "duration": 0.154127,
     "end_time": "2023-07-24T06:16:15.158325",
     "exception": false,
     "start_time": "2023-07-24T06:16:15.004198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_start_end(text):\n",
    "  text = f'<start> {text} <end>'\n",
    "  return text\n",
    "\n",
    "data_df.question = data_df.question.map(add_start_end)\n",
    "data_df.answer = data_df.answer.map(add_start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0603628e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:15.183297Z",
     "iopub.status.busy": "2023-07-24T06:16:15.181521Z",
     "iopub.status.idle": "2023-07-24T06:16:15.193920Z",
     "shell.execute_reply": "2023-07-24T06:16:15.192906Z"
    },
    "papermill": {
     "duration": 0.0264,
     "end_time": "2023-07-24T06:16:15.196117",
     "exception": false,
     "start_time": "2023-07-24T06:16:15.169717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; well  i thought we d start with pronun...</td>\n",
       "      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n",
       "      <td>&lt;start&gt; okay    then how  bout we try out some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; you re asking me out   that s so cute ...</td>\n",
       "      <td>&lt;start&gt; forget it  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; no  no  it s my fault    we didn t hav...</td>\n",
       "      <td>&lt;start&gt; cameron  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; gosh  if only we could find kat a boyf...</td>\n",
       "      <td>&lt;start&gt; let me see what i can do  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>&lt;start&gt; well that one  the one who keeps looki...</td>\n",
       "      <td>&lt;start&gt; ft could be you flatter yourself coghi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>&lt;start&gt; choose your targets men  that s right ...</td>\n",
       "      <td>&lt;start&gt; keep steady  you re the best shots of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>&lt;start&gt; colonel durnford    william vereker  i...</td>\n",
       "      <td>&lt;start&gt; good ones  yes  mr vereker  gentlemen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>&lt;start&gt; your orders  mr vereker  &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n",
       "      <td>&lt;start&gt; lord chelmsford seems to want me to st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       <start> well  i thought we d start with pronun...   \n",
       "1       <start> not the hacking and gagging and spitti...   \n",
       "2       <start> you re asking me out   that s so cute ...   \n",
       "3       <start> no  no  it s my fault    we didn t hav...   \n",
       "4       <start> gosh  if only we could find kat a boyf...   \n",
       "...                                                   ...   \n",
       "139404  <start> well that one  the one who keeps looki...   \n",
       "139405  <start> choose your targets men  that s right ...   \n",
       "139406  <start> colonel durnford    william vereker  i...   \n",
       "139407             <start> your orders  mr vereker  <end>   \n",
       "139408  <start> i m to take the sikali with the main c...   \n",
       "\n",
       "                                                   answer  \n",
       "0       <start> not the hacking and gagging and spitti...  \n",
       "1       <start> okay    then how  bout we try out some...  \n",
       "2                                <start> forget it  <end>  \n",
       "3                                  <start> cameron  <end>  \n",
       "4                 <start> let me see what i can do  <end>  \n",
       "...                                                   ...  \n",
       "139404  <start> ft could be you flatter yourself coghi...  \n",
       "139405  <start> keep steady  you re the best shots of ...  \n",
       "139406  <start> good ones  yes  mr vereker  gentlemen ...  \n",
       "139407  <start> i m to take the sikali with the main c...  \n",
       "139408  <start> lord chelmsford seems to want me to st...  \n",
       "\n",
       "[139409 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f043aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:15.220862Z",
     "iopub.status.busy": "2023-07-24T06:16:15.220081Z",
     "iopub.status.idle": "2023-07-24T06:16:15.225777Z",
     "shell.execute_reply": "2023-07-24T06:16:15.224869Z"
    },
    "papermill": {
     "duration": 0.019903,
     "end_time": "2023-07-24T06:16:15.227770",
     "exception": false,
     "start_time": "2023-07-24T06:16:15.207867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>'\n",
    "  )\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1118629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:15.251428Z",
     "iopub.status.busy": "2023-07-24T06:16:15.250591Z",
     "iopub.status.idle": "2023-07-24T06:16:25.885309Z",
     "shell.execute_reply": "2023-07-24T06:16:25.884210Z"
    },
    "papermill": {
     "duration": 10.649245,
     "end_time": "2023-07-24T06:16:25.887927",
     "exception": false,
     "start_time": "2023-07-24T06:16:15.238682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_sequence, question_tokenizer = tokenize(data_df.question)\n",
    "answer_sequence, answer_tokenizer = tokenize(data_df.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59f863b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:25.914667Z",
     "iopub.status.busy": "2023-07-24T06:16:25.912975Z",
     "iopub.status.idle": "2023-07-24T06:16:25.956547Z",
     "shell.execute_reply": "2023-07-24T06:16:25.955510Z"
    },
    "papermill": {
     "duration": 0.058821,
     "end_time": "2023-07-24T06:16:25.958847",
     "exception": false,
     "start_time": "2023-07-24T06:16:25.900026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125468, 29), (13941, 29), (125468, 32), (13941, 32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(question_sequence, \n",
    "                answer_sequence, test_size = 0.1, random_state=42) \n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e73eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:25.984124Z",
     "iopub.status.busy": "2023-07-24T06:16:25.983396Z",
     "iopub.status.idle": "2023-07-24T06:16:25.990933Z",
     "shell.execute_reply": "2023-07-24T06:16:25.989979Z"
    },
    "papermill": {
     "duration": 0.022827,
     "end_time": "2023-07-24T06:16:25.993463",
     "exception": false,
     "start_time": "2023-07-24T06:16:25.970636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "2---> <start>\n",
      "80---> yeah\n",
      "13---> that\n",
      "8---> s\n",
      "11002---> blush\n",
      "36---> on\n",
      "32---> my\n",
      "301---> wife\n",
      "3384---> uses\n",
      "9---> it\n",
      "3---> <end>\n",
      "\n",
      "Answer\n",
      "2---> <start>\n",
      "204---> ask\n",
      "5535---> travis\n",
      "22---> he\n",
      "7---> s\n",
      "6---> the\n",
      "1765---> ladies\n",
      "104---> man\n",
      "3---> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print('%d---> %s' % (t, lang.index_word[t]))\n",
    "\n",
    "print('Question')\n",
    "convert(question_tokenizer, x_train[0])\n",
    "print()\n",
    "print('Answer')\n",
    "convert(answer_tokenizer, y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc629a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:26.019017Z",
     "iopub.status.busy": "2023-07-24T06:16:26.018141Z",
     "iopub.status.idle": "2023-07-24T06:16:26.023480Z",
     "shell.execute_reply": "2023-07-24T06:16:26.022598Z"
    },
    "papermill": {
     "duration": 0.020398,
     "end_time": "2023-07-24T06:16:26.025551",
     "exception": false,
     "start_time": "2023-07-24T06:16:26.005153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_inp_size = len(question_tokenizer.word_index)+1\n",
    "vocab_tar_size =  len(answer_tokenizer.word_index)+1\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57306def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:26.050779Z",
     "iopub.status.busy": "2023-07-24T06:16:26.049871Z",
     "iopub.status.idle": "2023-07-24T06:16:30.783473Z",
     "shell.execute_reply": "2023-07-24T06:16:30.782344Z"
    },
    "papermill": {
     "duration": 4.748939,
     "end_time": "2023-07-24T06:16:30.786293",
     "exception": false,
     "start_time": "2023-07-24T06:16:26.037354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(x, y, batch_size=32):\n",
    "  data = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "  data = data.shuffle(1028)\n",
    "  data = data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "  data = data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  return data\n",
    "\n",
    "train_dataset = create_dataset(x_train, y_train)\n",
    "test_dataset = create_dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40dc4ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:30.811544Z",
     "iopub.status.busy": "2023-07-24T06:16:30.811227Z",
     "iopub.status.idle": "2023-07-24T06:16:30.905934Z",
     "shell.execute_reply": "2023-07-24T06:16:30.904780Z"
    },
    "papermill": {
     "duration": 0.109825,
     "end_time": "2023-07-24T06:16:30.908197",
     "exception": false,
     "start_time": "2023-07-24T06:16:30.798372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:(32, 29)\n",
      "[[    2    20     4    26    72   115  2451    35    41     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   144    13  1198     4     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    92   333    15    64     7    52    14     7    20     9     7\n",
      "     73    18     5    23    31    64     7    26    12     9    15     3\n",
      "      0     0     0     0     0]\n",
      " [    2    12   144    13    93     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    48    12    20     5    88    42     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    16  1538     3     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   106    21    11    20     9     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    38    35    30   763 12853     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   323    38   221    29    17   117    74     6  5100     3     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5    23    39   506    47   273    11   119   343  1573     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  2721 15186   276     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    18    38    95     4   249   194 10581  1337     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5    71   100    55     7     6   329     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    62    62    15   475    50    66     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     9     8   979 11460   665     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5   677     4    15    50     9     8  3196   180    44   368\n",
      "    297  9230    50    13   689 10293     3     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    17   223   427  1381    19   165    43   210     6   897     3\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   181  8598     4   811    14    10   230     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    65    71     4   161    55     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     5    21    11    74    38     4    34   402    13   319    41\n",
      "     50   176  7531     9     8   237    53    16     3     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   133  2087     4    26    12     4   863     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    59     7     6   439  1049     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    77   490   123     3     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    12    15     9   359     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    72     8    57     6   397     3     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   433   274    55    22    57   180     3     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    18    44     5   123    39  1056    44    13     8   719   167\n",
      "      4     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    34     4   170    24     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2   126   869    32   148  2448     4    34   387    86  7265  1347\n",
      "   6073     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2    62    59   356    20     6   302   467     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2  1849    45     6   430   260     7   940     6   430     3     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     4    25   130     7    10   310   340     3     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n",
      "Answer:(32, 32)\n",
      "[[   2    4 1979 ...    0    0    0]\n",
      " [   2  267   59 ...    0    0    0]\n",
      " [   2    5   38 ...    0    0    0]\n",
      " ...\n",
      " [   2   61  188 ...    0    0    0]\n",
      " [   2    4   34 ...    0    0    0]\n",
      " [   2   51 7213 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "  for q, a in train_dataset.take(1):\n",
    "    print(f'Question:{q.shape}\\n{q}')\n",
    "  \n",
    "    print(f'Answer:{a.shape}\\n{a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cafcff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:30.936650Z",
     "iopub.status.busy": "2023-07-24T06:16:30.934984Z",
     "iopub.status.idle": "2023-07-24T06:16:30.943542Z",
     "shell.execute_reply": "2023-07-24T06:16:30.942596Z"
    },
    "papermill": {
     "duration": 0.024411,
     "end_time": "2023-07-24T06:16:30.945663",
     "exception": false,
     "start_time": "2023-07-24T06:16:30.921252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "      super(Encoder, self).__init__()\n",
    "\n",
    "      self.batch_size = batch_size\n",
    "      self.encoder_units = encoder_units\n",
    "      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "      self.gru = tf.keras.layers.GRU(self.encoder_units, \n",
    "                                           return_sequences=True,\n",
    "                                           return_state=True,\n",
    "                                           recurrent_initializer = 'glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d52dea80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:30.971315Z",
     "iopub.status.busy": "2023-07-24T06:16:30.970424Z",
     "iopub.status.idle": "2023-07-24T06:16:30.978851Z",
     "shell.execute_reply": "2023-07-24T06:16:30.977954Z"
    },
    "papermill": {
     "duration": 0.02311,
     "end_time": "2023-07-24T06:16:30.980867",
     "exception": false,
     "start_time": "2023-07-24T06:16:30.957757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "      super(Decoder, self).__init__()\n",
    "\n",
    "      self.batch_size = batch_size\n",
    "      self.decoder_units = decoder_units\n",
    "      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "      self.gru = tf.keras.layers.GRU(self.decoder_units, \n",
    "                                           return_sequences=True,\n",
    "                                           return_state=True,\n",
    "                                           recurrent_initializer = 'glorot_uniform')\n",
    "      \n",
    "      self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, hidden = self.gru(x, initial_state = hidden)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    x =  tf.nn.softmax(self.fc(output))\n",
    "    return x, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "518524bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:31.005495Z",
     "iopub.status.busy": "2023-07-24T06:16:31.005219Z",
     "iopub.status.idle": "2023-07-24T06:16:34.609489Z",
     "shell.execute_reply": "2023-07-24T06:16:34.608378Z"
    },
    "papermill": {
     "duration": 3.619279,
     "end_time": "2023-07-24T06:16:34.611879",
     "exception": false,
     "start_time": "2023-07-24T06:16:30.992600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (32, 29, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (32, 1024)\n"
     ]
    }
   ],
   "source": [
    "# vocab_inp_size = len(eng_tokenizer.word_index)+1\n",
    "# vocab_tar_size =  len(spn_tokenizer.word_index)+1\n",
    "# embedding_dim = 256\n",
    "# units = 1024\n",
    "# batch_size=32\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(q, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03684fcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.636939Z",
     "iopub.status.busy": "2023-07-24T06:16:34.636617Z",
     "iopub.status.idle": "2023-07-24T06:16:34.708902Z",
     "shell.execute_reply": "2023-07-24T06:16:34.707836Z"
    },
    "papermill": {
     "duration": 0.087445,
     "end_time": "2023-07-24T06:16:34.711067",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.623622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch size, vocab_size) (32, 27849)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n",
    "\n",
    "sample_decoder_output, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden)\n",
    "\n",
    "print ('Decoder output shape: (batch size, vocab_size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fba5d24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.736270Z",
     "iopub.status.busy": "2023-07-24T06:16:34.735465Z",
     "iopub.status.idle": "2023-07-24T06:16:34.746328Z",
     "shell.execute_reply": "2023-07-24T06:16:34.745415Z"
    },
    "papermill": {
     "duration": 0.025389,
     "end_time": "2023-07-24T06:16:34.748379",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.722990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the optimizer using the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# create the loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')\n",
    "\n",
    "# define the loss function for the training\n",
    "def loss_function(real, pred):\n",
    "  # create the mask to ignore the padding tokens\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  # mask shape == (batch_size, sequence_length)\n",
    "  # calculate the loss\n",
    "  loss_ = loss_object(real, pred)\n",
    "  # mask the loss\n",
    "  # how the mask works:\n",
    "  # if the value is 1, the loss is calculated\n",
    "  # if the value is 0, the loss is ignored\n",
    "    #[1,1,1,1,1,1,0,0,0,0,0] mask\n",
    "    # *\n",
    "    #[2,6,2,1,6,3,2,1,5,7,9] input\n",
    "    # =\n",
    "    #[2,6,2,1,6,3,0,0,0,0,0] output\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  # mask shape == (batch_size, sequence_length)\n",
    "\n",
    "  loss_ *= mask\n",
    "  # calculate the average loss per batch \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab04706d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.772416Z",
     "iopub.status.busy": "2023-07-24T06:16:34.772137Z",
     "iopub.status.idle": "2023-07-24T06:16:34.784255Z",
     "shell.execute_reply": "2023-07-24T06:16:34.783376Z"
    },
    "papermill": {
     "duration": 0.026574,
     "end_time": "2023-07-24T06:16:34.786387",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.759813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the training metric \n",
    "train_loss = tf.metrics.Mean(name='train loss')\n",
    "# create the testing metric \n",
    "test_loss =tf.metrics.Mean(name='test loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "973fdec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.810773Z",
     "iopub.status.busy": "2023-07-24T06:16:34.810451Z",
     "iopub.status.idle": "2023-07-24T06:16:34.819548Z",
     "shell.execute_reply": "2023-07-24T06:16:34.818638Z"
    },
    "papermill": {
     "duration": 0.02392,
     "end_time": "2023-07-24T06:16:34.821578",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.797658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the training step\n",
    "# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n",
    "@tf.function\n",
    "# define the training step \n",
    "def train_step(inputs, target, enc_hidden):\n",
    "  # the encoder_hidden is the initial hidden state of the encoder\n",
    "  # enc_hidden shape == (batch_size, hidden_size)\n",
    "\n",
    "  # inilaize the loss to zero\n",
    "  loss = 0\n",
    "  # create the gradient tape to record the gradient of the loss with respect to the weights\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # pass the input to the encoder\n",
    "    # enc_output shape == (batch_size, 49, hidden_size)\n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "    # using the encoder to get the encoder_output and the encoder_hidden\n",
    "    # using the encoder_hidden as the initial hidden state of the decoder\n",
    "    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n",
    "    # set the initial decoder hidden state to the encoder hidden state\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # create the start token \n",
    "    # start_token shape == (batch_size, 1)\n",
    "    # repeat the start token for the batch size times\n",
    "    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n",
    "    \n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    \n",
    "    for t in range(1, target.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "      # calculate the loss for the current time step using the loss function\n",
    "      loss += loss_function(target[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(target[:, t], 1)\n",
    "  # calculate the loss for the current batch\n",
    "  batch_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "  # get the trainable variables\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  # calculate the gradients using the tape \n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  # update the trainable variables\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  # add the loss to the training loss metric\n",
    "  train_loss(batch_loss)\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc2d7e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.847691Z",
     "iopub.status.busy": "2023-07-24T06:16:34.847400Z",
     "iopub.status.idle": "2023-07-24T06:16:34.855426Z",
     "shell.execute_reply": "2023-07-24T06:16:34.854375Z"
    },
    "papermill": {
     "duration": 0.023179,
     "end_time": "2023-07-24T06:16:34.857518",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.834339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the training step\n",
    "# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n",
    "@tf.function \n",
    "def test_step(inputs, target, enc_hidden):\n",
    "    # the encoder_hidden is the initial hidden state of the encoder\n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "    # inilaize the loss to zero\n",
    "    loss = 0\n",
    "    # pass the input to the encoder \n",
    "    # enc_output shape == (batch_size, 49, hidden_size) \n",
    "    # enc_hidden shape == (batch_size, hidden_size)\n",
    "    # using the encoder to get the encoder_output and the encoder_hidden\n",
    "    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n",
    "    # set the initial decoder hidden state to the encoder hidden state\n",
    "    dec_hidden = enc_hidden\n",
    "    # create the start token\n",
    "    # start_token shape == (batch_size, 1)\n",
    "    # repeat the start token for the batch size times\n",
    "    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n",
    "    for t in range(1, target.shape[1]):\n",
    "        # passing enc_output to the decoder with dec_hidden as the initial hidden state\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "        # calculate the loss for the current time step using the loss function \n",
    "        loss += loss_function(target[:, t], predictions)\n",
    "\n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(target[:, t], 1)\n",
    "    # calculate the loss for the current batch\n",
    "    batch_loss = (loss / int(target.shape[1]))\n",
    "    # add the batch loss to the test loss metric\n",
    "    test_loss(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ad5b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T06:16:34.883806Z",
     "iopub.status.busy": "2023-07-24T06:16:34.882953Z",
     "iopub.status.idle": "2023-07-24T08:51:06.427012Z",
     "shell.execute_reply": "2023-07-24T08:51:06.425918Z"
    },
    "papermill": {
     "duration": 9274.599958,
     "end_time": "2023-07-24T08:51:09.469785",
     "exception": false,
     "start_time": "2023-07-24T06:16:34.869827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4355/4356 [============================>.] - ETA: 0s  Model is saved\n",
      "##################################################\n",
      "Epoch #1\n",
      "Training Loss 1.412036657333374\n",
      "Testing Loss 1.2930021286010742\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  Model is saved\n",
      "##################################################\n",
      "Epoch #2\n",
      "Training Loss 1.1939808130264282\n",
      "Testing Loss 1.2875748872756958\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #3\n",
      "Training Loss 1.0445854663848877\n",
      "Testing Loss 1.3326396942138672\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #4\n",
      "Training Loss 0.9033865332603455\n",
      "Testing Loss 1.3932620286941528\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #5\n",
      "Training Loss 0.7976151704788208\n",
      "Testing Loss 1.4530177116394043\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #6\n",
      "Training Loss 0.7145829200744629\n",
      "Testing Loss 1.5128159523010254\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #7\n",
      "Training Loss 0.6492245197296143\n",
      "Testing Loss 1.5738979578018188\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #8\n",
      "Training Loss 0.5983908176422119\n",
      "Testing Loss 1.6311886310577393\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #9\n",
      "Training Loss 0.5598857402801514\n",
      "Testing Loss 1.681365728378296\n",
      "##################################################\n",
      "4355/4356 [============================>.] - ETA: 0s  ##################################################\n",
      "Epoch #10\n",
      "Training Loss 0.5295239686965942\n",
      "Testing Loss 1.7321252822875977\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "# set the epochs to 10\n",
    "EPOCHS = 10\n",
    "# set the old test loss to high number \n",
    "\n",
    "old_test_loss=1000000\n",
    "# create the training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset the training loss metric\n",
    "    train_loss.reset_states()\n",
    "    # reset the testing loss metric\n",
    "    test_loss.reset_states()\n",
    "\n",
    "    # initalize the hidden state of the encoder to zeros \n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    # create the training progress bar set the total number of batches to the length of the training dataset and the batch size to the test size\n",
    "    steps_per_epoch = answer_sequence.shape[0]//batch_size #=> 4356 batch in the dataset \n",
    "    bar = tf.keras.utils.Progbar(target=steps_per_epoch)\n",
    "    \n",
    "    count=0\n",
    "    # iterate over the training dataset \n",
    "    for (batch, (inputs, target)) in enumerate(train_dataset):\n",
    "        # update the progress bar\n",
    "     count += 1\n",
    "        # run the training step\n",
    "     batch_loss = train_step(inputs, target, enc_hidden)\n",
    "     bar.update(count)  # manually update the progress bar\n",
    "                                                  \n",
    "    \n",
    "    \n",
    "    # iterate over the testing dataset    \n",
    "    for (batch, (inputs, target)) in enumerate(test_dataset):\n",
    "     count += 1\n",
    "        # run the testing step\n",
    "     batch_loss = test_step(inputs, target, enc_hidden)\n",
    "    bar.update(count)\n",
    "    # save the best performance model on the test dataset \n",
    "    \n",
    "    if old_test_loss> test_loss.result():\n",
    "        # set the old test loss to the test loss \n",
    "        old_test_loss= test_loss.result()\n",
    "        encoder.save(filepath='/content/models/encoder')\n",
    "        decoder.save(filepath='/content/models/decoder')\n",
    "        print('Model is saved')\n",
    "    # print the training and testing loss\n",
    "    print('#' * 50)\n",
    "    print(f'Epoch #{epoch + 1}')\n",
    "    print(f'Training Loss {train_loss.result()}')\n",
    "    print(f'Testing Loss {test_loss.result()}')\n",
    "    print('#' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3300238b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:16.250267Z",
     "iopub.status.busy": "2023-07-24T08:51:16.249717Z",
     "iopub.status.idle": "2023-07-24T08:51:16.262947Z",
     "shell.execute_reply": "2023-07-24T08:51:16.262021Z"
    },
    "papermill": {
     "duration": 3.535903,
     "end_time": "2023-07-24T08:51:16.265076",
     "exception": false,
     "start_time": "2023-07-24T08:51:12.729173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the chatbot function\n",
    "# the chatbot function takes in the question as input and answers the input sentence \n",
    "def chatbot(sentence):\n",
    "  \n",
    "  # clean the input question sentence \n",
    "  sentence = clean_text(sentence)\n",
    "  # add the start token to the sentence\n",
    "  sentence =add_start_end(sentence)\n",
    "  # tokenize the sentence\n",
    "  inputs = question_tokenizer.texts_to_sequences([sentence])\n",
    "  # pad the sentence\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                         maxlen=29,\n",
    "                                                         padding='post')\n",
    "  \n",
    "  # initalize the hidden state of the encoder to zeros\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  # pass the sentence to the encoder with the hidden state as the initial hidden state\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "  # set the initial decoder hidden state to the encoder hidden state\n",
    "  dec_hidden = enc_hidden\n",
    "  # create the start token\n",
    "  # start_token shape == (batch_size, 1)\n",
    "  # repeat the start token for the batch size times\n",
    "  dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']], 0)\n",
    "  # create the result string\n",
    "  result = ''\n",
    "  # loop over the length of the sentence (32)\n",
    "\n",
    "  for t in range(32):\n",
    "    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n",
    "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # getting the predicted word index\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    # getting the predicted word using the predicted index\n",
    "    # add the predicted word to the result string \n",
    "    result += answer_tokenizer.index_word[predicted_id] + ' '\n",
    "    # if the predicted word is the <end> token then stop the loop\n",
    "    if answer_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      # remove the <start> and <end> tokens from the result string\n",
    "      result = result.replace('<start> ', '')\n",
    "      result = result.replace(' <end> ','')\n",
    "      # remove the <start> and <end> tokens from the sentence string\n",
    "      sentence = sentence.replace('<start> ', '')\n",
    "      sentence = sentence.replace(' <end>', '')\n",
    "      return  sentence, result\n",
    "\n",
    "    # using the predicted word as the next decoder input\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  # remove the <start> and <end> tokens from the result string\n",
    "  result = result.replace('<start> ', '')\n",
    "  result = result.replace('<end>','')\n",
    "  # remove the <start> and <end> tokens from the sentence string\n",
    "  sentence = sentence.replace('<start> ', '')\n",
    "  sentence = sentence.replace('<end>', '')\n",
    "  \n",
    "\n",
    "  \n",
    " \n",
    "  \n",
    "  # return the result string and the original sentence\n",
    "  return sentence, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c1efc22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:22.479109Z",
     "iopub.status.busy": "2023-07-24T08:51:22.478751Z",
     "iopub.status.idle": "2023-07-24T08:51:22.566554Z",
     "shell.execute_reply": "2023-07-24T08:51:22.565612Z"
    },
    "papermill": {
     "duration": 3.318361,
     "end_time": "2023-07-24T08:51:22.568915",
     "exception": false,
     "start_time": "2023-07-24T08:51:19.250554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('how are you today', 'i m fine')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot(\"how are you today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1306190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:28.701032Z",
     "iopub.status.busy": "2023-07-24T08:51:28.700662Z",
     "iopub.status.idle": "2023-07-24T08:51:28.901491Z",
     "shell.execute_reply": "2023-07-24T08:51:28.900553Z"
    },
    "papermill": {
     "duration": 3.364523,
     "end_time": "2023-07-24T08:51:28.903535",
     "exception": false,
     "start_time": "2023-07-24T08:51:25.539012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('what is the weather outside',\n",
       " 'yes yes the superstar is still there is no safe she will be there')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('what is the weather outside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40364530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:35.118848Z",
     "iopub.status.busy": "2023-07-24T08:51:35.118248Z",
     "iopub.status.idle": "2023-07-24T08:51:35.257815Z",
     "shell.execute_reply": "2023-07-24T08:51:35.256913Z"
    },
    "papermill": {
     "duration": 3.311816,
     "end_time": "2023-07-24T08:51:35.259992",
     "exception": false,
     "start_time": "2023-07-24T08:51:31.948176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('can you run', 'i m ahead of you keep your shirt on')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('can you run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ccfeda7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:41.584357Z",
     "iopub.status.busy": "2023-07-24T08:51:41.583457Z",
     "iopub.status.idle": "2023-07-24T08:51:41.742292Z",
     "shell.execute_reply": "2023-07-24T08:51:41.741325Z"
    },
    "papermill": {
     "duration": 3.411274,
     "end_time": "2023-07-24T08:51:41.744352",
     "exception": false,
     "start_time": "2023-07-24T08:51:38.333078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' how old ', 'i dunno probably right up there based on her resume')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot(' how old ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9110fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T08:51:48.327403Z",
     "iopub.status.busy": "2023-07-24T08:51:48.327041Z",
     "iopub.status.idle": "2023-07-24T08:51:48.384061Z",
     "shell.execute_reply": "2023-07-24T08:51:48.383153Z"
    },
    "papermill": {
     "duration": 3.668984,
     "end_time": "2023-07-24T08:51:48.386170",
     "exception": false,
     "start_time": "2023-07-24T08:51:44.717186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('can you play', 'of course')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('can you play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ef8f26",
   "metadata": {
    "papermill": {
     "duration": 3.247013,
     "end_time": "2023-07-24T08:51:54.616046",
     "exception": false,
     "start_time": "2023-07-24T08:51:51.369033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9375.158059,
   "end_time": "2023-07-24T08:52:00.666527",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-24T06:15:45.508468",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
